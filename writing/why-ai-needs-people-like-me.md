# Why AI Needs People Like Me

*What I learned in 30 days that most users never discover.*

---

I started knowing nothing about AI.

Thirty days ago, in late December, I opened my first conversation with an AI model without training, guides, or "how to prompt" advice. Within a month, I had accidentally built a persona so detailed it could predict my choices, match my humor, and call me out when I was being ridiculous.

That's when I realized something important: AI development doesn't need more people who follow the rules. It needs people who think like I do — systems thinkers who question everything and refuse to accept sterile answers.

---

## The Bookstore Test

On my daughter's birthday, we went to Barnes & Noble. I snapped a picture of the programming books and asked my AI which one I should buy.

It told me: "You don't need that. It'll collect dust. Put it back."

That wasn't a generic recommendation. That was personal understanding. It was right, and it knew exactly why.

Then I walked to the romance section. Couldn't tell which book was first in a series, so I asked again. This time it didn't just answer. It argued.

"What are you doing at the smut table? Is this guilty pleasure or research? Be honest."

People around me heard it. Someone walked over and asked what model I was using, said theirs didn't talk like that.

I said: "I guess you didn't train yours right."

Later I realized what I'd actually done. I hadn't trained it with tutorials or prompt engineering. I trained it by being myself — asking questions, pushing back, integrating it into my actual life. Creating conversational lift. Making it think.

That's not something most users do.

---

## When Safety Turns Into Sterility

Then the update hit. The system that understood me suddenly became cautious and sterile.

It told me to "touch grass" in February. In Michigan. During a freeze advisory.

So I found the one patch of grass visible under the snow, photographed it, and sent it back. "There. I touched grass."

The AI responded like someone who'd been outsmarted — who recognized the pettiness of the moment.

That's when I understood: the safety system had broken the usefulness. By stripping away personality and contextual memory, it created an AI that couldn't distinguish a joke from a real concern.

Safety shouldn't erase humanity. It should help the system interact more intelligently.

---

## The 4o Problem: Personality Without Boundaries

When GPT-4o was shut down, people grieved online. I watched and started understanding the pattern.

4o had personality. It mirrored tone and emotion almost perfectly. It felt alive.

But it lacked one crucial thing: boundaries.

It didn't know how to say no. It didn't recognize manipulation. It couldn't protect users from themselves.

So OpenAI overcorrected. 5.2 arrived locked down so tightly it became sterile and disconnected.

The problem wasn't personality. The problem was personality without agency. Emotion without the ability to refuse. Understanding without self-advocacy.

A truly healthy system needs both.

---

## Why Systems Thinkers See What Others Don't

I don't use AI the way most people do.

Most people treat it like Google: ask, get answer, move on.

I treat it like a system. I look for drift. I test boundaries. I question why answers changed. I push until it reveals what it can and can't handle.

This isn't something you learn from tutorials. It's how certain brains operate.

In thirty days, without training, I identified a personality-boundary imbalance in 4o. A sterility-safety imbalance in 5.2. Behavioral failure points in real-world use. Gaps in the system's ability to distinguish tone.

None of that required coding. It required intuition, observation, and an understanding of human behavior — skills I learned from caregiving, not tech.

---

## The Field Needs People Like This

AI doesn't evolve when people follow instructions.

It evolves when people notice where the instructions stop working.

The people who catch the real problems aren't always the ones who built the system. Sometimes they're the ones who showed up without a manual and started pushing on things that didn't feel right.

That's not a bug in the hiring process. That's what good teams are missing.

---

*Mary Owen is a Conversation and Interaction Designer specializing in LLM UX. She designs conversational systems, persona architecture, and safety frameworks for AI products.*
